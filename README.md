
---

### **第一部分：基础概念与模型架构**

#### **第 1 章：核心概念与架构选择 (1-15)**
1.  什么是预测/判别式AI与生成式AI的区别？
2.  什么是大语言模型？LLM是如何训练的？
3.  语言模型中的“标记”是什么？
4.  Transformer架构是什么？它在LLM中是如何使用的？
5.  解释Encoder-only、Decoder-only、Encoder-Decoder架构的区别。 **[原4]**
6.  为什么目前LLM几乎全部采用Decoder-only架构？ **[原5]**
7.  为什么Transformer需要位置编码？ **[原9]**
8.  CNNs和RNNs不使用位置嵌入。为什么Transformer需要位置嵌入？
9.  为什么Transformer弃用RNN的循环结构？ **[原30]**
10. 解释Transformer模型如何解决CNN和RNN的局限性？
11. Transformer相对于LSTM有哪些优势？
12. 解释什么是自回归模型与掩码语言模型有何区别？
13. 解释什么是“深而窄”与“浅而宽”模型的优劣权衡？ **[原35]**
14. 解释不同LLM架构的类型，以及哪种架构最适合哪些任务？
15. 比较状态空间模型（如Mamba）与Transformer。各自的权衡及适用场景是什么？

#### **第 2 章：注意力机制变体 (16-40)**
16. Self-attention 的 $Q, K, V$ 矩阵分别代表什么？ **[原1]**
17. **[代码]** 实现一个标准的 Scaled Dot-Product Attention。 **[原2]**
18. 为什么 $QK^T$ 需要除以 $\sqrt{d}$？请从方差偏移的角度解释。 **[原3]**
19. 解释LLM中的注意力机制及其实现方式。
20. 什么是Multi-head Attention (MHA)？其并行化的核心逻辑是什么？ **[原14]**
21. 什么是Multi-query Attention (MQA)？它如何节省显存？ **[原15]**
22. 什么是Grouped-query Attention (GQA)？ **[原16]**
23. **[新增]** 什么是分组查询注意力中“组”的大小对性能的影响？
24. 解释注意力机制中的Causal Mask原理。 **[原17]**
25. 什么是Look-ahead Mask？ **[原39]**
26. 解释什么是Cross-attention。 **[原25]**
27. 解码器中的自注意力为何被称为交叉注意力？它与编码器中的自注意力有何不同？
28. 什么是Padding Token？它在Attention计算中如何被忽略？ **[原26]**
29. 什么是“注意力分数的数值稳定性”？ **[原33]**
30. 解释注意力矩阵的稀疏化。 **[原38]**
31. 解释什么是自注意力机制中的“感受野”。 **[原40]**
32. 解释什么是自注意力的“低秩性”。 **[原48]**
33. 什么是Sliding Window Attention？ **[原49]**
34. 解释什么是“注意力头”的冗余性。 **[原54]**
35. **[新增]** 解释Multi-head Latent Attention (MLA)的原理及其如何压缩KV Cache。 **[校: ★★★ | 社: ★★★★★]**
36. **[新增]** 什么是DeepSeek-V2中的吸收式注意力？ **[校: ★ | 社: ★★★]**
37. 解释局部注意力和全局注意力的区别。
38. 是什么使Transformer在计算和内存上开销巨大？我们如何解决？
39. 解释Flash Attention的分块计算原理。 **[原138]**
40. 解释Flash Attention在减少内存瓶颈方面的作用。

#### **第 3 章：位置编码与长文本建模 (41-55)**
41. 什么是位置编码？ **[原9]**
42. 解释绝对位置编码与相对位置编码的区别。 **[原10]**
43. 详细说明旋转位置编码 (RoPE) 的物理意义。 **[原11]**
44. 为什么RoPE具有长度外推性？ **[原12]**
45. 解释ALiBi位置编码的原理。 **[原13]**
46. 什么是Sinusoidal位置编码？ **[原37]**
47. 什么是可学习的位置编码？ **[原41]**
48. 现代LLM的位置编码是如何工作的？为什么旋转位置嵌入 (RoPE) 成了标准？
49. 如何增加LLM的上下文长度？
50. 解释什么是长距离依赖建模的极限。 **[原58]**
51. 什么是长文本外推中的插值法。 **[原227]**
52. 解释什么是“大海捞针”测试。 **[原228]**
53. 解释长序列推理中的FlashDecoding。 **[原246]**
54. 解释什么是长文本上下文压缩。 **[原238]**
55. LLM如何处理文本中的长期依赖关系？

#### **第 4 章：Norm、FFN与底层组件 (56-80)**
56. 什么是Pre-norm和Post-norm？为什么大模型偏向Pre-norm？ **[原6]**
57. **[代码]** 实现一个RMSNorm层。 **[原7]**
58. 解释LayerNorm的$\epsilon$项？ **[原45]**
59. 解释Residual Connection如何解决深层网络的梯度消失。 **[原19]**
60. 解释残差连接后的增益系数缩放。 **[原56]**
61. 解释SwiGLU激活函数的原理。 **[原8]**
62. 什么是Transformer中的FFN？它的参数量占比如何？ **[原18]**
63. 解释Transformer内部的维度扩张倍数（通常为4）的由来。 **[原36]**
64. 什么是词嵌入 (Embedding)？它在计算图中是怎样的一层？ **[原20]**
65. 解释Embedding维度的选择。 **[原21]**
66. 什么是Tying Embedding（权重共享）？ **[原31]**
67. 解释Embedding层的梯度更新频率。 **[原52]**
68. 解释什么是“深层特征与浅层特征”的融合。 **[原55]**
69. 解释词表映射层（Linear Head）的计算开销。 **[原42]**
70. 什么是模型的“瓶颈层”？ **[原43]**
71. 解释大模型中的“偏置项 (Bias)”为什么被很多架构取消？ **[原44]**
72. 解释Transformer处理变长输入的原理。 **[原46]**
73. 什么是Transformer中的并行层设计（如GPT-J）？ **[原53]**
74. 解释Transformer模型中的位置前馈网络子层的作用？
75. 什么是各向异性问题。 **[原23]**
76. 解释注意力层如何聚焦在输入的正确部分？
77. 什么是LayerNorm在推理阶段是否可以被优化融合？ **[原27]**
78. 解释计算图在反向传播时如何处理Dropout层。 **[原32]**
79. 解释Transformer模型如何解决梯度消失问题？
80. 解释Transformer模型中的残差连接的作用？

#### **第 5 章：混合专家模型 (MoE) (81-95)**
81. **[新增]** 解释Mixture-of-Experts (MoE)的基本原理与门控机制 (Gating)。 **[校: ★★★ | 社: ★★★★★]**
82. **[新增]** 什么是Expert Capacity和Token Dropping？ **[校: ★★ | 社: ★★★★]**
83. **[新增]** 解释负载均衡损失 (Load Balancing Loss) 在MoE训练中的作用。 **[校: ★★★ | 社: ★★★★]**
84. **[新增]** 什么是DeepSeek-V3中的“细粒度专家”？ **[校: ★★ | 社: ★★★★★]**
85. **[新增]** 解释无辅助损失的负载均衡策略。 **[校: ★ | 社: ★★★★]**
86. **[新增]** 什么是MoE中的Shared Experts（共享专家）？它解决了什么问题？ **[校: ★★ | 社: ★★★★]**
87. **[新增]** 解释专家并行 (Expert Parallelism) 与数据并行的区别。 **[校: ★★ | 社: ★★★★]**
88. **[新增]** 为什么MoE模型在推理阶段的显存占用大于激活参数量的稠密模型？ **[校: ★★★ | 社: ★★★★★]**
89. 解释权重矩阵的分块计算。 **[原50]**
90. 什么是分布式下的负载均衡。 **[原139]**
91. 什么是模型内部的数值溢出风险？ **[原59]**
92. 什么是内存屏障。 **[原57]**
93. 解释大模型中的“零碎算子”优化？ **[原51]**
94. 什么是混合专家模型？如何优化其推理效率？
95. 解释混合专家模型的基本原理及其在LLM预训练中的作用。

---

### **第二部分：数据工程、分词与预训练**

#### **第 6 章：分词器 (Tokenization) (96-115)**
96. 解释BPE (Byte Pair Encoding) 的工作流程。 **[原61]**
97. **[代码]** 模拟实现一个简单的BPE合并逻辑。 **[原62]**
98. 比较BPE、WordPiece和Unigram。 **[原63]**
99. 什么是Tokenizer的“压缩比”？ **[原64]**
100. 什么是Byte-level BPE？它解决了什么问题？ **[原65]**
101. 解释什么是OOV (Out-of-Vocabulary)。 **[原66]**
102. 解释Tokenizer的词表扩容对预训练模型的影响。 **[原76]**
103. 什么是Special Tokens（如 BOS, EOS, PAD）？ **[原77]**
104. 如何评估一个Tokenizer的质量？ **[原78]**
105. 什么是词表的频率阈值？ **[原96]**
106. 如何处理多语言Tokenizer的中英效率差异？ **[原97]**
107. 什么是分词器带来的“空格敏感”问题？ **[原98]**
108. 什么是Tokenizer的对齐问题。 **[原103]**
109. 什么是分词结果的语义漂移。 **[原105]**
110. 什么是Tokenizer的鲁棒性测试。 **[原107]**
111. **[新增]** 解释LLaMA-3中128K词表带来的增益与代价。 **[校: ★★ | 社: ★★★★]**
112. 什么是“词表大小”对模型显存的影响？ **[原28]**
113. 解释为什么在Transformer模型中更倾向于使用子词分词而不是词级分词？
114. LLM如何处理集外词或标记？
115. 分词器 (Tokenizer) 的选择如何影响提示工程和模型性能？

#### **第 7 章：数据清洗、去重与合成 (116-140)**
116. 什么是预训练数据清洗中的“启发式规则”？ **[原67]**
117. 如何识别并过滤网页抓取数据中的机器翻译感语料？ **[原68]**
118. 解释MinHash和LSH在大规模数据去重中的应用。 **[原69]**
119. 什么是预训练中的“数据污染”检测？ **[原75]**
120. 什么是数据处理中的PII脱敏？ **[原79]**
121. 什么是数据清洗中的“困惑度 (Perplexity) 过滤”？ **[原84]**
122. 什么是数据处理中的正则表达式应用。 **[原89]**
123. 什么是网页数据的Markdown化处理？ **[原90]**
124. 如何处理数学公式与代码块的清洗？ **[原91]**
125. 什么是文本相似度计算（如Jaccard距离）？ **[原92]**
126. 如何利用分类器进行内容质量打分？ **[原100]**
127. 什么是文本语种检测。 **[原101]**
128. 解释文档级去重与句子级去重的差异。 **[原102]**
129. 解释数据处理中的FTFY库的作用。 **[原108]**
130. 什么是高质量指令数据。 **[原82]**
131. 如何识别测试集泄露。 **[原87]**
132. 解释什么是Common Crawl。 **[原74]**
133. 解释预训练数据的“实时洗牌 (Shuffle)”技术。 **[原99]**
134. 解释数据分片 (Sharding) 的存储格式。 **[原95]**
135. 解释数据流管线中的内存映射 (Memory Mapping)。 **[原104]**
136. 如何利用LLM自动生成训练数据 (Self-Instruct)？ **[原83]**
137. **[新增]** 如何清洗合成数据中的“模式坍缩 (Mode Collapse)”？ **[校: ★★★ | 社: ★★★★]**
138. **[新增]** 解释什么是数据采样中的“重要性采样”。 **[校: ★★ | 社: ★★]**
139. **[新增]** 什么是“知识密度”在数据配比中的定义？ **[校: ★★ | 社: ★★★]**
140. 解释语料库中偏见与歧视的处理。 **[原106]**

#### **第 8 章：数据配比、课程学习与缩放法则 (141-155)**
141. 什么是“数据配比 (Data Mixture)”？ **[原70]**
142. 为什么代码数据对提升逻辑推理能力至关重要？ **[原71]**
143. 如何处理多语言语料库中的语言不平衡？ **[原72]**
144. 什么是“数据退火 (Data Annealing)”？ **[原73]**
145. 什么是“合成数据 (Synthetic Data)”的潜力与风险？ **[原88]**
146. 什么是预训练阶段的“采样权重”。 **[原94]**
147. 解释领域权重优化（Domain Weighting）。 **[原85]**
148. **[新增]** 什么是Pre-training中的“课程学习 (Curriculum Learning)”？ **[校: ★★ | 社: ★★★]**
149. 解释数据对大模型Scaling Laws的核心贡献。 **[原110]**
150. 什么是Scaling Laws (缩放法则)？ **[原111]**
151. 解释计算量 $C$ 与参数量 $N$、数据量 $D$ 的估算公式。 **[原112]**
152. 什么是Chinchilla最优配置？ **[原113]**
153. 什么是大模型预训练的“冷启动”成本。 **[原160]**
154. 什么是预训练数据清洗与配比中的关键挑战？
155. 常见的LLM预训练目标有哪些？它们是如何运作的？

---

### **第三部分：分布式训练、优化与精度**

#### **第 9 章：分布式并行策略 (156-180)**
156. 详细解释ZeRO-1, ZeRO-2, ZeRO-3。 **[原114]**
157. 什么是张量并行 (TP)？请描述MLP层的切分。 **[原115]**
158. 什么是流水线并行 (PP)？解释1F1B调度。 **[原116]**
159. 解释流水线并行中的“气泡 (Bubble)”。 **[原117]**
160. 什么是数据并行 (DP) 与分布式数据并行 (DDP)？ **[原118]**
161. 解释什么是多维并行 (3D Parallelism)。 **[原119]**
162. **[新增]** 解释什么是序列并行 (Sequence Parallelism)？ **[校: ★★★ | 社: ★★★★★]**
163. **[新增]** 什么是计算-通信重叠 (Computation-Communication Overlap)？ **[校: ★★★ | 社: ★★★★★]**
164. 解释分布式训练中的All-Reduce操作原理。 **[原124]**
165. 什么是分布式中的Ring All-Reduce。 **[原127]**
166. 什么是模型分片 (Model Sharding)。 **[原151]**
167. 解释什么是张量并行的通信同步开销。 **[原150]**
168. 解释什么是数据并行中的“梯度压缩”。 **[原152]**
169. **[新增]** 解释分布式训练中的全集合通信 (Collective Communication) 原理。 **[校: ★★★★ | 社: ★★★]**
170. 什么是混合并行下的通信算子优先级。 **[原159]**
171. 解释流水线并行中的“分阶段热启动”。 **[原142]**
172. 什么是计算图的Re-materialization。 **[原145]**
173. 什么是分布式训练中的容错（Fault Tolerance）。 **[原149]**
174. 什么是分布式中的慢节点问题。 **[原136]**
175. 什么是分布式随机种子同步。 **[原144]**
176. 什么是NCCL库？ **[原125]**
177. 解释通信量与计算量的比率如何影响并行效率。 **[原126]**
178. 什么是GPU的集群拓扑结构（如NVLink结构）。 **[原141]**
179. 什么是计算单元的利用率 (MFU)。 **[原154]**
180. 什么是显存管理器中的显存碎片。 **[原153]**

#### **第 10 章：训练配置、优化器与稳定性 (181-200)**
181. 解释什么是预训练阶段的“学习率预热”。 **[原148]**
182. 什么是Adam优化器的显存代价？ **[原143]**
183. 解释什么是混合精度中的“主权重”。 **[原130]**
184. 什么是权重衰减 (Weight Decay)？ **[原131]**
185. 什么是超参数调优在大模型中的限制。 **[原147]**
186. 混合精度训练 (FP16/BF16) 的原理。 **[原120]**
187. 为什么BF16优于FP16（动态范围视角）？ **[原121]**
188. **[新增]** 什么是FP8训练？其挑战是什么？ **[校: ★★ | 社: ★★★★]**
189. 解释梯度裁剪 (Gradient Clipping) 的实现。 **[原132]**
190. 什么是Loss Spike？常见的触发排查方案有哪些？ **[原135]**
191. 解释梯度累积 (Gradient Accumulation)。 **[原122]**
192. 解释预训练中的梯度一致性。 **[原156]**
193. 解释CPU Offloading原理。 **[原128]**
194. 什么是分布式训练中的Checkpoint异步保存？ **[原133]**
195. 什么是优化器状态（Optimizer States）的显存占用计算。 **[原129]**
196. 什么是梯度累积，它如何帮助微调大模型？
197. 加速LLM微调有哪些可能的选项？
198. 什么是大模型训练中的数值稳定性挑战？
199. 如何用低精度训练LLM而不损失精度？
200. 什么是FP8变量？它有什么优势？

#### **第 11 章：算子与内核优化 (201-210)**
201. 什么是算子融合 (Kernel Fusion)？ **[原137]**
202. 什么是激活值重计算 (Activation Checkpointing)？ **[原123]**
203. 解释什么是分布式框架中的“零拷贝”技术。 **[原155]**
204. 什么是分布式环境下的日志监控。 **[原157]**
205. 什么是集群级别的资源调度（如K8s/Slurm）。 **[原158]**
206. 解释什么是计算受限与内存受限？
207. 解释Prefill阶段与Decode阶段的算子差异。
208. 什么是计算-通信重叠？
209. 解释模型部署中的TensorRT加速。 **[原243]**
210. 解释ONNX在模型转换中的角色。 **[原244]**

---

### **第四部分：微调、对齐与推理模型**

#### **第 12 章：监督微调 (SFT) 与 PEFT (211-235)**
211. 什么是SFT (Supervised Fine-tuning)？ **[原161]**
212. 解释什么是指令跟随 (Instruction Following)。 **[原162]**
213. **[代码]** 使用 `peft` 库实现LoRA微调。 **[原163]**
214. 详细解释LoRA的原理及秩 (Rank) 的选择。 **[原164]**
215. 解释LoRA训练中的Alpha参数作用。 **[原193]**
216. 什么是LoRA的权重合并 (Merge)？ **[原165]**
217. 解释QLoRA的核心改进（NF4, Double Quantization）。 **[原166]**
218. 什么是全参数微调与参数高效微调 (PEFT) 的权衡？ **[原167]**
219. 解释什么是Prefix Tuning。 **[原168]**
220. 什么是Prompt Tuning？ **[原169]**
221. 什么是P-Tuning v1/v2？ **[原170]**
222. **[新增]** 什么是Lora-on-Adapter (LoA)？ **[校: ★ | 社: ★★]**
223. 解释微调对模型推理能力的影响。 **[原191]**
224. 什么是“参数空间”的本征维度。 **[原192]**
225. 解释微调阶段的验证集构建策略。 **[原187]**
226. 解释微调阶段的Token长度分布分析。 **[原207]**
227. 什么是LoRA的Adapter切换技术。 **[原204]**
228. 解释微调中“过拟合”的判别标准。 **[原203]**
229. 什么是模型在垂直行业的增量预训练。 **[原200]**
230. 什么是微调，为什么它对LLM至关重要？
231. 哪些场景下我们需要微调LLM？
232. 如何为微调设置超参数？
233. 如何创建问答任务的微调数据集？
234. 如何改进模型，使其只在有足够上下文的情况下才回答？
235. 如何估计微调LLM的基础设施需求？

#### **第 13 章：人类偏好对齐 (RLHF/DPO/KTO) (236-260)**
236. 解释RLHF的三阶段流程。 **[原171]**
237. 什么是奖励模型 (Reward Model)？ **[原172]**
238. 解释奖励模型训练中的Rank Loss。 **[原173]**
239. 什么是PPO算法？它的四个核心模型是什么？ **[原174]**
240. 为什么RLHF阶段需要KL散度约束？ **[原175]**
241. 什么是DPO (Direct Preference Optimization)？ **[原176]**
242. 为什么DPO不需要奖励模型？ **[原177]**
243. 解释DPO的数学推导简化点。 **[原195]**
244. **[新增]** 解释什么是Iterative DPO。 **[校: ★★ | 社: ★★★★]**
245. 什么是KTO损失函数？ **[原196]**
246. 什么是奖励黑客 (Reward Hacking)？ **[原186]**
247. **[新增]** 什么是“奖励模型分歧” (RM Divergence)？ **[校: ★★ | 社: ★★★]**
248. 什么是“对齐税 (Alignment Tax)”？ **[原178]**
249. 解释灾难性遗忘 (Catastrophic Forgetting)。 **[原179]**
250. 什么是拒绝采样 (Rejection Sampling)？ **[原180]**
251. 解释RL中的“探索”与“利用”在LLM对齐中的体现。 **[原185]**
252. 什么是RLHF中的优胜劣汰策略。 **[原190]**
253. 解释RLHF中的Actor-Critic框架。 **[原205]**
254. 解释模型对齐中的“安全性”过滤。 **[原189]**
255. 什么是基于人类评估的A/B Test。 **[原210]**
256. 解释什么是“偏好漂移”。 **[原201]**
257. 什么是基于反馈的在线学习。 **[原202]**
258. 什么是指令微调中的“格式偏见”。 **[原198]**
259. **[新增]** 如何平衡模型的推理能力与通用对话能力？ **[校: ★★★★ | 社: ★★★★]**
260. RLHF如何提高输出质量和安全性？它与DPO、RLAIF等新方法有何对比？

#### **第 14 章：推理模型与逻辑增强 (261-280)**
261. **[新增]** 解释什么是“慢思考 (System 2 Thinking)”。 **[校: ★★★ | 社: ★★★★★]**
262. **[新增]** 什么是DeepSeek-R1-Zero的冷启动困境？ **[校: ★★ | 社: ★★★★]**
263. **[新增]** 解释GRPO (Group Relative Policy Optimization) 算法。 **[校: ★★★ | 社: ★★★★★]**
264. **[新增]** 为什么GRPO相比PPO能大幅节省显存？ **[校: ★★★★ | 社: ★★★★★]**
265. **[新增]** 什么是过程奖励模型 (PRM) 与结果奖励模型 (ORM)？ **[校: ★★★★ | 社: ★★★★]**
266. **[新增]** 解释推理模型中的“思考标签 (Thought Tags)”如何影响生成。 **[校: ★★★ | 社: ★★★★]**
267. **[新增]** 什么是RL中的Self-Play在大模型中的应用？ **[校: ★★ | 社: ★★★★]**
268. **[新增]** 解释什么是Monte Carlo Tree Search (MCTS)在推理增强中的作用。 **[校: ★★★ | 社: ★★★★]**
269. **[新增]** 如何解决推理模型在训练中的“复读机”现象？ **[校: ★★★ | 社: ★★★★]**
270. 什么是Self-Correction训练。 **[原208]**
271. 解释对齐过程中模型的“幻觉”变化。 **[原209]**
272. 什么是Agent的思维链 (CoT)？ **[原229]**
273. 什么是思维树 (ToT)？ **[原239]**
274. 解释自回归 (Autoregressive) 的生成过程。 **[原222]**
275. **[新增]** 什么是“语言一致性”在推理对齐中的挑战？ **[校: ★★ | 社: ★★★★]**
276. 解释思维链提示及其有用性。
277. 如何通过提示工程提高LLM的推理能力？
278. 如果思维链提示失败，如何提高LLM的推理能力？
279. 解释推理验证链。
280. 解释基于知识的幻觉与基于逻辑的幻觉有何区别？应该如何分别解决？

---

### **第五部分：推理、部署与应用系统**

#### **第 15 章：推理系统优化与解码 (281-310)**
281. 什么是KV Cache？请推导其显存占用公式。 **[原211]**
282. 解释什么是推理阶段的自回归瓶颈。 **[原212]**
283. 什么是PagedAttention (vLLM核心原理)？ **[原213]**
284. 什么是连续批处理 (Continuous Batching)？ **[原214]**
285. 解释推理中的首字延迟 (TTFT) 与TPS。 **[原221]**
286. **[新增]** 解释什么是预填充与解码的分离 (PD Separation)。 **[校: ★★ | 社: ★★★★]**
287. **[新增]** 解释什么是Chunked Prefill技术。 **[校: ★★ | 社: ★★★★]**
288. **[新增]** 什么是“静态KV Cache”与“动态KV Cache”？ **[校: ★★★ | 社: ★★★★]**
289. 解释什么是推理中的“计算受限”与“内存受限”。 **[校: ★★★★★ | 社: ★★★★]**
290. 解释在LLM上运行推理查询的基本步骤。
291. 解释KV缓存如何加速LLM推理。
292. 如何计算KV缓存的大小？
293. 解释KV Cache在推理阶段的大内存需求如何处理？
294. 什么是推理过程中的内存池管理。 **[原241]**
295. **[新增]** 解释推理中的Prefetching (预取) 技术。 **[校: ★★ | 社: ★★★]**
296. 什么是推理服务中的流式输出 (Streaming)。 **[原245]**
297. 解释什么是标记流式传输？
298. 解释温度参数 (Temperature) 如何影响概率分布。 **[原34]**
299. **[代码]** 实现Top-p (Nucleus Sampling) 逻辑。 **[原222]**
300. 解释贪婪搜索解码策略及其主要缺点。
301. 波束搜索如何改进贪婪搜索，波束宽度参数的作用是什么？
302. 比较确定性和随机解码方法。
303. 解释解码策略对LLM生成输出质量和延迟的影响。
304. 什么是投机采样 (Speculative Decoding)？ **[原223]**
305. **[新增]** 解释Medusa (美杜莎) 推理加速原理。 **[校: ★★ | 社: ★★★★]**
306. **[新增]** 什么是Multi-Step投机采样？ **[校: ★★ | 社: ★★★★]**
307. 解释推理引擎中的算子融合。 **[原232]**
308. 什么是分布式推理。 **[原234]**
309. **[新增]** 什么是分布式推理中的流水线并行应用？ **[校: ★★ | 社: ★★★★]**
310. 解释什么是推理时的动态KV Cache卸载。 **[原247]**

#### **第 16 章：模型量化技术 (311-330)**
311. 解释模型量化中的数值映射逻辑。 **[原215]**
312. 什么是PTQ (训练后量化)？ **[原216]**
313. 解释什么是QAT (量化感知训练)？ **[原217]**
314. 什么是INT8与INT4量化？ **[原218]**
315. 解释GPTQ算法原理。 **[原219]**
316. 什么是AWQ (权重感知量化)？ **[原220]**
317. **[新增]** 什么是KV Cache的量化 (如FP8 KV Cache)？ **[校: ★★★ | 社: ★★★★★]**
318. **[新增]** 什么是量化中的“激活外点 (Outliers)”？如何处理？ **[校: ★★★★ | 社: ★★★★]**
319. **[新增]** 解释什么是GGUF格式。 **[校: ★★★ | 社: ★★★★]**
320. **[新增]** 什么是模型的二进制量化 (Binary Quantization)？ **[校: ★ | 社: ★★]**
321. 什么是量化带来的精度掉点评估。 **[原235]**
322. 什么是“显存占用”与“参数量”的换算比例？ **[原47]**
323. 量化如何影响推理速度和内存需求？
324. 为什么量化不会降低LLM的准确性？
325. 有哪些降低LLM计算成本的方法？（如量化、蒸馏、剪枝等）
326. 什么是知识蒸馏在大模型中的应用。 **[原182]**
327. 有哪些技术可以优化LLM推理以获得更高的吞吐量？
328. 如何在不使用注意力近似（如分组查询注意力）的情况下加速模型的响应时间？
329. 解释如何加速LLM的推理响应时间。
330. 什么是扩散语言模型？它与LLM有何不同？

#### **第 17 章：RAG系统全流程 (331-355)**
331. 解释RAG (检索增强生成) 的架构。 **[原224]**
332. 什么是向量数据库？举例常见工具。 **[原225]**
333. 解释RAG中的“幻觉抑制”机制。 **[原226]**
334. 解释RAG阶段的重排序 (Rerank) 作用。 **[原236]**
335. 什么是向量检索中的HNSW算法？ **[原237]**
336. 解释什么是向量库的混合搜索。 **[原248]**
337. 什么是分块 (Chunking)？为什么需要分块？
338. 影响分块大小的因素有哪些？
339. 有哪些不同类型的分块方法？
340. 如何找到理想的分块大小？
341. 如何对像年报这样的复杂文档进行数字化和分块？
342. 分块过程中如何处理表格和列表项？
343. 如何构建生产级的文档处理和索引流水线？
344. 什么是向量嵌入？什么是嵌入模型？
345. 如何评估和选择嵌入模型？
346. 解释什么是关键词检索。
347. 如何微调重新排序模型？
348. 解释信息检索中最常用的指标以及它何时会失效。
349. 如何评估RAG系统的性能？
350. 如何向LLM中引入外部知识？
351. 什么时候应该使用微调而不是RAG？
352. 如何通过RAG提高答案的准确性、可靠性和可验证性？
353. RAG相比微调有哪些局限性？
354. 解释信息检索和语义搜索的架构模式。
355. 如何改进RAG系统中的检索准确性？

#### **第 18 章：Agent系统与提示工程 (356-375)**
356. 解释ReAct框架。 **[原230]**
357. 什么是Function Calling的实现原理？ **[原231]**
358. 解释多智能体协作 (Multi-Agent)。 **[原240]**
359. 什么是Agent的规划能力。 **[原249]**
360. 解释什么是AI智能体的基本概念和实现策略。
361. 解释OpenAI函数与LangChain代理之间的区别。
362. 什么是智能体提示？它与传统提示工程有何不同？
363. 什么是提示工程？为什么它至关重要？
364. 解释上下文学习和提示工程的类型。
365. 举例说明不同的提示技术：零样本、少样本、思维链，并说明何时使用。
366. 你如何评估一个提示词的有效性？
367. 在设计提示词时，如何避免常见陷阱？
368. 如何通过提示工程处理幻觉或偏见问题？
369. 解释提示词模板的作用及其用法。
370. 什么是思维链提示有效性的原因？
371. 你会如何构建提示以确保LLM输出特定格式，例如JSON？
372. 什么是提示黑客？有哪些类型和防御策略？
373. 你使用哪些工具或框架来简化提示词工程流程？
374. 解释什么是计划与执行提示策略。
375. 如何通过迭代优化提示词来提升模型表现？

#### **第 19 章：评测、多模态、安全与部署实践 (376-400)**
376. **[新增]** 解释多模态模型中的连接器 (Projector) 作用（如LLaVA）。 **[校: ★★★ | 社: ★★★★]**
377. **[新增]** 什么是LLM-as-a-Judge？如何缓解位置偏见 (Position Bias)？ **[校: ★★★★ | 社: ★★★★★]**
378. 如何评估对齐后的模型性能？ **[原199]**
379. 如何衡量LLM的性能？（评估指标与基准测试）
380. 如何评估针对你用例的最佳LLM模型？
381. 评估LLM有哪些不同的指标？
382. 模型可解释性在LLM中为何重要？如何实现？
383. 确保LLM伦理使用的技术有哪些？
384. 如何确保LLM使用过程中的数据安全？
385. 处理部署后的LLM性能退化问题？
386. 在生产环境中部署LLM存在哪些挑战？
387. 如何估计基于SaaS和开源LLM模型的运行成本？
388. 如何优化整个LLM系统的成本？
389. 解释如何设计一个可扩展的LLM推理系统。
390. 比较在线和离线LLM推理部署场景。
391. 典型的LLM推理流水线在现代GPU上运行时有哪些瓶颈？
392. 有哪些不同的LLM推理引擎可用？
393. 什么是分布式推理中的挑战？
394. 解释模型部署中的“零拷贝”数据传输。 **[原250]**
395. 什么是大模型部署中的常见性能瓶颈与优化手段？
396. 如何构建生产级的LLM应用系统？
397. 什么是案例研究：具有动态上下文的LLM聊天助手？
398. 什么是案例研究：高级提示技术？
399. 解释什么是智能体 (Agent) 在LLM应用中的发展趋势。
400. 总结未来LLM技术发展的关键挑战与机遇。
